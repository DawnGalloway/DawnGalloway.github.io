[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "myblog",
    "section": "",
    "text": "senior project\n\n\nForecast\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2022\n\n\nDawn Galloway\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsenior project\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2022\n\n\nDawn Galloway\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "DGalloway_Resume.html",
    "href": "DGalloway_Resume.html",
    "title": "Lijia Yu’s resume",
    "section": "",
    "text": "Lijia Yu\n\n\n\n\n\n dawn.n.galloway@gmail.com\n github.com/DawnGalloway\n linkedin.com/in/dawnngalloway/\n +1 206-245-0710\n\n\n\n\n\nExperienced in statistical analysis, statistical learning models, and optimization methods.\nFull experience with next generation sequencing data analysis.\nHighly skilled in R, Bash, Perl, Python, LaTeX\n\n\n\n\nThis resume was made with the R package pagedown.\nLast updated on 2022-11-28."
  },
  {
    "objectID": "DGalloway_Resume.html#title",
    "href": "DGalloway_Resume.html#title",
    "title": "Lijia Yu’s resume",
    "section": "Dawn Galloway",
    "text": "Dawn Galloway\n\nRBDC faculty liaison and sales."
  },
  {
    "objectID": "DGalloway_Resume.html#employment",
    "href": "DGalloway_Resume.html#employment",
    "title": "Lijia Yu’s resume",
    "section": "Employment",
    "text": "Employment\n\nDigital Engineering & Data Science Intern\nIdaho National Laboratory - Battelle Energy Alliance, LLC\nIdaho Falls, Idaho\nMarch 2022 - Present\n• Created forecast comparisons in R Markdown with the Forecast, Fable, and FKF packages in R which resulted in an order of magnitude improvement in accuracy • Made improvements to GUI using Vue2 and Vueplotly • Created, visualized, and presented Yolov5 experiment project plan\n\n\nData Science Project Lead\nRexburg Business Development Center for Stotz Equipment\nRexburg, Idaho\nJanuary 2022 - April 2022\n• Led team to create R package for client which pulls weather information from Mesonet and crop date from Snowflake to track and predict growing degree units • Troubleshoot project issues, research resources • Assign student consultants tasks based on experience and interest\n\n\nDepartment Office Assistant\nBrigham Young Univerity - Idaho\nRexburg, Id\nApril 2019 - October 2021\n• Received an award from the Department Chair for efficiency and contributions • Hired, trained, and led 3-5 student office employees per semester • Reduced time on calls by over 50% by redirecting commonly misdirected and generic calls, as well as, increasing visibility of commonly requested information"
  },
  {
    "objectID": "DGalloway_Resume.html#related-experience-and-volunteering",
    "href": "DGalloway_Resume.html#related-experience-and-volunteering",
    "title": "Lijia Yu’s resume",
    "section": "Related Experience and Volunteering",
    "text": "Related Experience and Volunteering\n\nData Science Society Boot Camp Instructor\nBrigham Young University - Idaho\nRexburg, Idaho\nApril 2022 - Present, September 2021 - December 2021\n\n\nData Science Consultant\nRexburg Development Business Center\nRexburg, Idaho\nSeptember 2021 - December 2021\n• Accessed weather API using the RNOA and RNPN packages to assist in predicting harvest dates based on crop and planting date • Discovered alternate data source with greater data breadth and predictive data • Presented findings to client\n\n\nData Science Consultant/Project Manager\nRexburg Business Development Center\nRexburg, Idaho\nApril 2021 - July 2021\n• Assigned tasks, led discussions, tracked project progress • Pulled machine data from John Deer API to help solve business problem\n\n\nData Science Society Officer\nBrigham Young University - Idaho\nApril 2021 - July 2021\n\n\nData Science Consultant\nRexburg Business Development Center\nRexburg, Idaho\nJanuary 2021 - April 2021\n• Contributed to Shiny dashboard for STEM occupation webpage for a local college • Created sample Shiny dashboard for Project Manager"
  },
  {
    "objectID": "DGalloway_Resume.html#education",
    "href": "DGalloway_Resume.html#education",
    "title": "Lijia Yu’s resume",
    "section": "Education",
    "text": "Education\n\nBrigham Young University - Idaho\nB.S. Data Science with Computer Science minor (in progress)\nExpected Graduation July 2024\n\n\nCertificates\nData Science Certificate, April 2021\nProgramming - Computer Science, December 2018"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dawn Galloway",
    "section": "",
    "text": "LinkedIn"
  },
  {
    "objectID": "posts/first_post/index.html",
    "href": "posts/first_post/index.html",
    "title": "Senior Project",
    "section": "",
    "text": "For my senior project, I will be comparing forecasting methods and speeds in order to take advantage of recent performance improvements in the data warehouse at my place of employment. Though I won’t be able to share details, I will post tips and tricks for the packages I will be using and will share useful advice I learn about time series characteristics such as trends and seasonality, statistical concepts like autocorrelation and partial autocorrelation, and methods like ETS, TBATS, and ARIMA.\nSome of the packages I plan to use:\n\nForecast: A well known package for forecasting with time series. See: Automatic Time Series Forecasting: The forecast Package for R\nFable: Essentially version three of the Forecast package, but renamed as it now works with tsibbles. See: Fable\nFKF: Fast Kalman Filter. See: The Fast Kalman Filter\nKFAS: Exponential Family State Space Models in R.\nBenchmark: A package for performance comparisons. See: Microbenchmark"
  },
  {
    "objectID": "posts/forecast/index.html",
    "href": "posts/forecast/index.html",
    "title": "The Magic of Forecast",
    "section": "",
    "text": "The first thing you need to know about the Forecast package is that there is an incredibly helpful text by Rob J Hyndman and George Athanasopoulos titled Forecasting: Principles and Practice which explains relevant concepts and walks through almost every function with examples. If you would like to work through their examples, you can download the fpp2 package which includes Forecast and all of the data. I wish every package had such a helpful guide.\nSome other useful resources:\n\nThe Forecast package manual and vignette is available here\nHyndsight, Rob J. Hyndman’s blog\nCross Validated, Stack Exchange’s Q&A for Statistical Topics\n\nHyndman pretty actively answers questions both on his blog and on Cross Validated, so I suggest reading the comments if your question isn’t answered in a blog entry.\n\n\n\nWhen they refer to a time series, they are not referring to data with time information. They are referring to a specific data type, the time series. Unlike a data frame or tibble, there isn’t a column for times, rather a time series has a starting point, an ending point, and a frequency. Typically, a frequency of 1 is annual, 4 is quarterly, 12 is monthly, and so on.\n\n#install.packages(\"fpp2\")\nlibrary(fpp2)\nhead(austourists)\n\n         Qtr1     Qtr2     Qtr3     Qtr4\n1999 30.05251 19.14850 25.31769 27.59144\n2000 32.07646 23.48796                  \n\nhead(goog200)\n\nTime Series:\nStart = 1 \nEnd = 6 \nFrequency = 1 \n[1] 392.8300 392.5121 397.3059 398.0113 400.4902 408.0957\n\n\nThe International Tourists to Australia data has quartly data with a start year of 1999, while the start for the Google daily closing stock price is arbitrary, representing an undated year.\nThe forecast package has some functions which are wrappers that, given data and a forecast horizon, call another function followed by a call to forecast(). For example, holt() calls ets() to fit the data and then forecast(). I found it useful for my purposes to call these functions separately as it allowed me greater control.\n\n\n\nForecast: Principles and Practices explains the forecasting methods and underlying math well, so I won’t duplicate their efforts, but I will share my notes in an attempt to save others time.\n\n\nThe findfrequency function can calculate the frequency in your data. This can be a useful check to ensure that your frequency assumption is correct before working with your data. I worked with data that we did not expect would have a frequency, but findfrequency() found a frequency of five. This caused me to test seasonal as well as non-seasonal forecast methods. The downside of this function is that in data with multiple frequencies, it will only return the most dominant one. In the case of the Australian tourists data, it returns a half-yearly frequency rather than quarterly.\n\nfindfrequency(austourists)\n\n[1] 2\n\n\nSimilarly, the functions ndiffs() and nsdiffs() will return the number of times the given data needs to be differenced in order to become stationary. The type of unit root test used can be set with the test argument set to “kpss”, “adf”, or “pp”. Remember that the null hypothesis for the KPSS test is the opposite of the hypothesis for the Augmented Dickey-Fuller and Phillips-Perron test.\n\ngoogd <- ndiffs(goog200)\npaste(googd ,\" difference is needed to make the goog200 data stationary.\")\n\naustd <- nsdiffs(austourists)\npaste(austd ,\" difference is needed to make the austourists data stationary.\")\n\n[1] \"1  difference is needed to make the goog200 data stationary.\"\n[1] \"1  difference is needed to make the austourists data stationary.\"\n\n\nForecast has functions like autoplot(), autolayer(), ggLagplot(), ggHistogram(), ggAcf(), and ggPacf(), which take package models and use ggplot to create appropriate plots. This simplifies the plotting process while allowing you to add to plots in the same way one would with any ggplot. Below I added a title, theme, and color to the line.\n\nautoplot(austourists) + \n  ggtitle(\"International Tourists Visits to Australia in Millions\") +\n  geom_line(color=austourists) +\n  theme_classic()\n\n\n\n\n Below I use the Holt method on the data twice, once with the damping argument set to TRUE with phi of 0.9 and once with it set to FALSE. This example is in the text, but with different data (Fpp2 7.2). When the damped argument is set to NULL, both options are tried and the best one is returned.\n\ntraining <- window(austourists, end=c(2010,4))\n\nfc <- holt(training, h=15)\nfc2 <- holt(training, damped=TRUE, phi = 0.9, h=15)\nautoplot(training) +\n  autolayer(fc, series=\"Holt's method\", PI=FALSE) +\n  autolayer(fc2, series=\"Damped Holt's method\", PI=FALSE) +\n  ggtitle(\"Forecasts from Holt's method\") + xlab(\"Year\") +\n  ylab(\"Air passengers in Australia (millions)\") +\n  guides(colour=guide_legend(title=\"Forecast\")) +\n  theme_classic()\ntail(austourists)\n\n         Qtr1     Qtr2     Qtr3     Qtr4\n2014                   54.76076 59.83447\n2015 73.25703 47.69662 61.09777 66.05576\n\n\n\n\n\nWith the Forecast package, it’s easy to check residuals and accuracy.\n\ncheckresiduals(fc)\n\n\n    Ljung-Box test\n\ndata:  Residuals from Holt's method\nQ* = 88.192, df = 4, p-value < 2.2e-16\n\nModel df: 4.   Total lags used: 8\n\n(fc_acc <- accuracy(fc, austourists))\n\n                     ME     RMSE      MAE        MPE     MAPE     MASE\nTraining set  0.9211998 6.571903 5.097607 -0.6464137 14.95336 1.778292\nTest set     -0.7941557 8.899599 7.198491 -4.4212146 14.65768 2.511182\n                   ACF1 Theil's U\nTraining set -0.2619964        NA\nTest set     -0.3637125 0.5573859\n\n\n\n\n\nValues in these objects can be easily accessed, most with base R’s $, though the accuracy values are stored as a matrix and must be referenced accordingly. For example, the test MAPE, 14.6576754, can be accessed with object_name[2,5].\n\n\n\n\nForecast imports several packages including stats, tseries, and urca. These also have some useful functions:\n\nFrom urca, the kpss test.\nFrom tseries, the adf.test\nFrom stats, the Box.test as well as start(), end(), time(), cycle(), and deltaat() which are helpful when working with time series because the times don’t exist as an accessible column in the data structure."
  }
]